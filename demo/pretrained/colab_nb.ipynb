{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "agct-music demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO7z6gqV_L_a",
        "colab_type": "text"
      },
      "source": [
        "## Preparation\n",
        "Make sure you choose GPU as Hardware accelerator when configuring the runtime (Runtime -> Change runtime type)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBPIlBya1fJU",
        "colab_type": "text"
      },
      "source": [
        "#### Installing the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSydC76x05Ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pypianoroll\n",
        "!pip install --upgrade torch\n",
        "import pypianoroll  # this will install ffmpeg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTTv7z9b3MZM",
        "colab_type": "text"
      },
      "source": [
        "#### Getting the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvFawC-C3PJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create ssh keys (the public key is installed on gitlab)\n",
        "import os, stat\n",
        "os.mkdir(\"/root/.ssh\")\n",
        "with open(\"/root/.ssh/id_ed25519.pub\", \"w\") as pubkey, open(\"/root/.ssh/id_ed25519\", \"w\") as privkey:\n",
        "    pubkey.write(\"ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOaO3EXB/jrEp4cYg5DBj/9yWh3W/X7/xro2iDMOy0ht root@6147081228e3\\n\")\n",
        "    privkey.write(\"-----BEGIN OPENSSH PRIVATE KEY-----\\n\")\n",
        "    privkey.write(\"b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\\n\")\n",
        "    privkey.write(\"QyNTUxOQAAACDmjtxFwf46xKeHGIOQwY//clod1v1+/8a6NogzDstIbQAAAJhPsrlvT7K5\\n\")\n",
        "    privkey.write(\"bwAAAAtzc2gtZWQyNTUxOQAAACDmjtxFwf46xKeHGIOQwY//clod1v1+/8a6NogzDstIbQ\\n\")\n",
        "    privkey.write(\"AAAECFjHPM4aI4nSseqXCjUJkomo3uOZTx6A2DLJW+e1FI1uaO3EXB/jrEp4cYg5DBj/9y\\n\")\n",
        "    privkey.write(\"Wh3W/X7/xro2iDMOy0htAAAAEXJvb3RANjE0NzA4MTIyOGUzAQIDBA==\\n\")\n",
        "    privkey.write(\"-----END OPENSSH PRIVATE KEY-----\\n\")\n",
        "os.chmod(\"/root/.ssh/id_ed25519\", stat.S_IREAD|stat.S_IWRITE)\n",
        "# add domain to know hosts\n",
        "!ssh-keyscan -t ed25519 gitlab.com > ~/.ssh/known_hosts\n",
        "!git clone git@gitlab.com:agct_music/music-autoencoder.git\n",
        "os.chdir(\"./music-autoencoder\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjVxPJT5_IF_",
        "colab_type": "text"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuhJiWZk6MwT",
        "colab_type": "text"
      },
      "source": [
        "#### Creating a model\n",
        "We create the model described in the concept, with default parameters. To use a model that is more like the one in the tutorial, create an instance of ```model.autoencoder.Autoencoder``` instead (without ```_SE```).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llvkZkm93byT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import model.autoencoder\n",
        "autoencoder = model.autoencoder.Autoencoder_SE()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbCkSTn-8df8",
        "colab_type": "text"
      },
      "source": [
        "#### Loading training data\n",
        "We can use the small dataset ```small.zip``` for testing and debugging. The archive should contain only ```.json``` (or ```.txt```) files, where each file represents one *song*. The word *song* is used to refer to a 3-tuple containing:\n",
        "0. The name of the song (```str```).\n",
        "1. The duration of a time tick (```float```).\n",
        "2. The stream of tokens (a list of tuples containing two ```int```).\n",
        "\n",
        "The dataset is split into training set and evaluation set with ratio 0.8 to 0.2. Both ```trainset``` and ```evalset``` will be a Python list of songs. Because the songs are not shuffled, the first 0.8 fraction of the songs (in order they appear in the archive) will belong to the training set.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpPsE9wP8lEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import util.archive\n",
        "trainset, evalset = util.archive.load(\"small.zip\", 0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JNgpo2j_saR",
        "colab_type": "text"
      },
      "source": [
        "#### Training the model\n",
        "We train the model on the training set for 7 epochs. During training, the accuracy when not using TF (first value in bracket) and when using TF (second value in bracket) is shown. Non-TF predictions sometimes show a higher accuracy because the first prediction, which is never teacher forced, is often correct - especially when the input sequences are read in reverse.\n",
        "\n",
        "After each epoch, the loss and accuracy of each song in the evaluation set is computed. The name of the song is also displayed. \n",
        "\n",
        "It is possible to send all output to a file, that can then be read and results can be plotted. The code takes about 6 minutes to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h16U9FGw_0MJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import train\n",
        "train.train(autoencoder, 7, trainset, evalset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2L9aRA2Bo88",
        "colab_type": "text"
      },
      "source": [
        "#### Saving the model weights\n",
        "Each model from ```model.autoencoder``` provides a ```save``` function that saves the model parameters and weights to a directory. A new direcotry will be created if it does not already exist. The parameters are saved in a ```.json``` file, so that you can tell which model is which. (Only the parameters to the constructor are saved.)\n",
        "\n",
        "We also save the names of all the songs we used for training, so that we can later reconstruct the training set (if needed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t4BnBkhBobv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir = os.path.join(\"demo\", \"model\")\n",
        "autoencoder.save(dir)\n",
        "# save the name of the training and eval songs\n",
        "with open(os.path.join(dir, \"train.txt\"), \"w\") as t, open(os.path.join(dir, \"eval.txt\"), \"w\") as e:\n",
        "    for name, _, _ in trainset:\n",
        "        t.write(name+\"\\n\")\n",
        "    for name, _, _ in evalset:\n",
        "        e.write(name+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fStCJAfGDcK0",
        "colab_type": "text"
      },
      "source": [
        "## Working with a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNRWL89gQuet",
        "colab_type": "text"
      },
      "source": [
        "#### Loading as saved model\n",
        "We provide a pre-trained model. It was trained with the first 1000 songs from ```all.zip``` over 7 epochs. It was actually created by running the file ```main.py``` as is.\n",
        "\n",
        "The file ```params.json``` in the model directory shows what the model parameters were."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvoOB9MHDbtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir = os.path.join(\"demo\", \"pretrained\")\n",
        "autoencoder = model.autoencoder.load(dir)\n",
        "# also show params.json\n",
        "with open(os.path.join(dir, \"params.json\")) as params:\n",
        "    print(params.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSNk9qolS6zn",
        "colab_type": "text"
      },
      "source": [
        "#### Visualizing the training accuracy\n",
        "The output generated during training was saved to ```demo/pretrained/train.log```. It can be visualized with ```util.readlog```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM9Wf62OS6Sq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import util.readlog\n",
        "util.readlog.plot(os.path.join(dir, \"train.log\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj7cZWqISaxS",
        "colab_type": "text"
      },
      "source": [
        "#### Loading MIDI files from a directory\n",
        "Some MIDI files that where excluded from the training set are provided. These can be loaded using ```util.load```. Converting a MIDI file to a token representation will take a while. It is usually faster to save/load the token representation rather than working with a MIDI file.\n",
        "\n",
        "Google drive can also be very slow. Instead of opening hundreds of files, it is often a good idea to save multiple songs in one archive - as was done for the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "280I64tGUdZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import util.load\n",
        "songs = util.load.midi(os.path.join(dir, \"midi\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC0X1FwNXFI4",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluating and saving\n",
        "The model can be used to encode and decode a set of songs. We can then save the reconstructions to listen to the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4ZAO5bvXO74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import eval, util.save\n",
        "pred = eval.eval(autoencoder, songs)\n",
        "# save songs with -pred attached to their names\n",
        "util.save.midi(os.path.join(dir, \"midi\"), [(name+\"-pred\", dur, toks) for name, dur, toks in pred])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQpB9ReWYADH",
        "colab_type": "text"
      },
      "source": [
        "#### Creating the AGCT datasets\n",
        "We can extract the code vectors of the songs and save them into a format readable by AGCT. The resulting file can then be processed by AGCT.\n",
        "\n",
        "To keep the gene names short, samples from the first song will be named ```A_1```, ```A_2```, ..., samples from the second song will be called ```B_1```, ```B_2```, ..., and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScMrKKl9lt7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import encode\n",
        "c = encode.encode(autoencoder, songs[0:5])\n",
        "util.save.code(os.path.join(dir, \"agct_dataset.txt\"), c)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}